# Resumo da Aula 3: Modelos LLM, Tokens, Transformadores e Engenharia de Prompt

## Conceito de Modelos LLM

Na terceira aula, foi explicado o conceito de **Modelos de Linguagem de Grande Escala (LLMs)**, explorando como esses modelos operam usando **tokens** e **transformers** para processar e gerar linguagem natural. Discutimos o funcionamento desses modelos, a manipulação de grandes conjuntos de dados e as etapas envolvidas em seu treinamento.

## Engenharia de Prompt

Foi abordada a **Engenharia de Prompt**, destacando a importância de projetar prompts eficazes para obter respostas precisas dos modelos LLM. A aula também abordou como as **tags** influenciam o comportamento dos modelos, otimizando a geração de respostas alinhadas ao objetivo da aplicação.

## Ferramentas Baixadas e Configuração

Após a explicação teórica, passamos para a configuração prática, onde foram realizadas as seguintes etapas:

1. **Finalizar Exemplo Docker:** Concluímos o exemplo iniciado na aula anterior, demonstrando a execução de aplicações com Docker.

2. **Baixar Ferramentas Essenciais para LLMs:**
   - **LLM Studio**
   - **Anything LLM**
   - **Ollama**

Essas ferramentas foram baixadas e configuradas para facilitar o trabalho com modelos de linguagem e permitir uma gestão mais eficaz dos recursos de IA.

## Download e Organização dos Modelos

Foram baixados modelos específicos, que devem ser salvos no seguinte diretório:
```d
C:\Users\<SEU_USUARIO>\.cache\lm-studio\models
